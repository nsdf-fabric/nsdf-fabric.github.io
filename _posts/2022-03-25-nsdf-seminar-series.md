---
layout: post
title: Pangeo Forge - Crowdsourcing Analysis Ready Data in the Cloud
---

# Invited speaker at the National Science Data Fabric Seminar Series

## 12:30 pm ET April 28 2022


Analysis-ready, cloud optimized (ARCO) scientific data is essential for scalable big data analytics in the cloud. 
ARCO can massively accelerate statistical analysis, visualization, and machine learning workflows on large-scale scientific datasets. 
However, most scientific data is distributed in archival formats that are not optimized for large-scale analysis. 

Pangeo Forge (https://pangeo-forge.org/) is an open source framework for data Extraction, Transformation, and Loading (ETL) of scientific data. 
The goal of Pangeo Forge is to make it easy to extract data from traditional data archives and deposit it in cloud object storage in ARCO format.

Pangeo Forge is made of two main components:

- Pangeo Forge Recipes: an open source Python package, which allows you to create and run ETL pipelines (“recipes”) and run them on your own computer.
- Pangeo Forge Cloud: a cloud-based automation framework which executes these recipes in the cloud from code stored in GitHub and deposits the data into cloud object storage.

By storing data recipes in version-controlled GitHub repositories, we can maintain perfect provenance information from archival repository to ARCO copy. 
Using Pangeo Forge, we are collaboratively populating a petabyte-scale library of open ARCO climate data distributed across multiple cloud storage services, 
including Open Storage Network.

Pangeo Forge is inspired directly by Conda Forge, a community-led collection of recipes for building conda packages. 
We hope that Pangeo Forge can eventually play the same role for datasets, encouraging open, interdisciplinary collaboration around data curation.

Bio: https://github.com/rabernat#short-biography

![image](https://user-images.githubusercontent.com/1260735/160108618-072ee48e-464c-4241-ad11-19b60add9b26.png)
